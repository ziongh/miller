{
  "content": "## Goal: Build the Best Symbol Overview Tool for AI Agents\n\nMiller's `get_symbols` will be better than Julie's by leveraging Python's ML capabilities\nto provide not just structure, but **intelligence about the code**.\n\n---\n\n## Success Criteria\n\n**Feature Parity with Julie:**\n- \u2705 Multiple reading modes (structure/minimal/full)\n- \u2705 Max depth control (0=top-level, 1=methods, 2+=nested)\n- \u2705 Target filtering with partial matching\n- \u2705 Limit parameter for large files\n- \u2705 Body extraction (mode=\"full\" returns implementation)\n- \u2705 Workspace filtering (primary vs reference)\n\n**Miller's Enhancements (Better Than Julie):**\n- \u2705 Semantic relevance scores for filtered symbols\n- \u2705 Usage frequency indicators (how often symbol is referenced)\n- \u2705 Documentation quality scores (highlight undocumented code)\n- \u2705 Related symbols suggestions (using embeddings)\n- \u2705 Cross-language variant hints (symbol has naming variants in other langs)\n- \u2705 Symbol importance ranking (PageRank on call graph)\n- \u2705 Performance: <50ms for typical files, <200ms for large files\n\n---\n\n## Phase 1: Feature Parity with Julie (Foundation)\n\n### Task 1.1: Reading Modes\n- [ ] Implement \"structure\" mode (default): names, kinds, signatures, locations\n- [ ] Implement \"minimal\" mode: names and kinds only (ultra-compact)\n- [ ] Implement \"full\" mode: everything including body/implementation\n\n### Task 1.2: Depth Control\n- [ ] Add max_depth parameter (0=top-level only, 1=include methods, 2+=nested)\n- [ ] Implement depth filtering in tree-sitter traversal\n- [ ] Test with deeply nested code (classes in classes in modules)\n\n### Task 1.3: Target Filtering\n- [ ] Add target parameter (symbol name to filter)\n- [ ] Implement partial matching (case-insensitive substring)\n- [ ] Return matching symbols + their children (up to max_depth)\n\n### Task 1.4: Limit & Pagination\n- [ ] Add limit parameter (max symbols to return)\n- [ ] Implement smart limiting (preserve hierarchy when limiting)\n- [ ] Add \"truncated\" indicator if limit reached\n\n### Task 1.5: Workspace Filtering\n- [ ] Support workspace parameter (\"primary\" or workspace_id)\n- [ ] Query appropriate workspace database\n- [ ] Handle reference workspace symbol resolution\n\n**Tests:**\n- [ ] Test each mode with Python, TypeScript, Rust files\n- [ ] Test depth control (0, 1, 2, 3)\n- [ ] Test target filtering with partial matches\n- [ ] Test limit with large files (500+ symbols)\n- [ ] Test workspace filtering with reference workspace\n\n---\n\n## Phase 2: Python/ML Enhancements (Better Than Julie)\n\n### Task 2.1: Semantic Relevance Scores\n**Goal:** When filtering by target, rank results by semantic relevance\n\n```python\n# Example: get_symbols(\"auth.py\", target=\"login\")\n# Returns symbols ranked by relevance:\n# 1. \"login\" (exact match) - score: 1.0\n# 2. \"handle_login\" (contains target) - score: 0.8\n# 3. \"authenticate_user\" (semantically similar) - score: 0.6\n```\n\n**Implementation:**\n- [ ] Compute embeddings for symbol names + signatures\n- [ ] Calculate cosine similarity between target and symbols\n- [ ] Add \"relevance_score\" field to output\n- [ ] Sort by relevance when target specified\n\n### Task 2.2: Usage Frequency Indicators\n**Goal:** Show how \"important\" each symbol is based on usage\n\n```python\n# Example output:\n# {\n#   \"name\": \"calculateAge\",\n#   \"kind\": \"Function\",\n#   \"usage_frequency\": \"high\",  # Referenced 47 times\n#   \"references_count\": 47\n# }\n```\n\n**Implementation:**\n- [ ] Query symbol_relationships table for reference counts\n- [ ] Add reference_count field\n- [ ] Add usage_frequency tier (low/medium/high/very_high)\n- [ ] Thresholds: low=1-5, medium=6-20, high=21-50, very_high=50+\n\n### Task 2.3: Documentation Quality Scores\n**Goal:** Highlight undocumented code (help agents prioritize what needs docs)\n\n```python\n# Example:\n# {\n#   \"name\": \"processPayment\",\n#   \"doc_quality\": \"poor\",  # No docstring\n#   \"has_docs\": false,\n#   \"doc_comment\": null\n# }\n```\n\n**Implementation:**\n- [ ] Check if doc_comment exists and is non-empty\n- [ ] Measure doc quality (length, completeness)\n- [ ] Add doc_quality field (none/poor/good/excellent)\n- [ ] Criteria: none=no docs, poor=<50 chars, good=50-200, excellent=200+\n\n### Task 2.4: Related Symbols Suggestions\n**Goal:** Suggest similar/related symbols using embeddings\n\n```python\n# Example: get_symbols(\"user.py\", target=\"User\")\n# Returns:\n# {\n#   \"name\": \"User\",\n#   \"related_symbols\": [\n#     {\"name\": \"UserProfile\", \"similarity\": 0.85},\n#     {\"name\": \"UserService\", \"similarity\": 0.78},\n#     {\"name\": \"UserRepository\", \"similarity\": 0.72}\n#   ]\n# }\n```\n\n**Implementation:**\n- [ ] Compute embedding for target symbol\n- [ ] Search vector_store for top-5 similar symbols\n- [ ] Filter to same file or closely related files\n- [ ] Add related_symbols field with similarity scores\n\n### Task 2.5: Cross-Language Variant Hints\n**Goal:** Show if symbol has variants in other languages (supports trace_call_path)\n\n```python\n# Example:\n# {\n#   \"name\": \"IUser\",\n#   \"language\": \"typescript\",\n#   \"cross_language_hints\": {\n#     \"has_variants\": true,\n#     \"variants_count\": 3,\n#     \"languages\": [\"python\", \"csharp\", \"sql\"]\n#   }\n# }\n```\n\n**Implementation:**\n- [ ] Generate naming variants for symbol (snake, camel, pascal, etc.)\n- [ ] Query database for variants in different languages\n- [ ] Add cross_language_hints field\n- [ ] Include variant count and languages found\n\n### Task 2.6: Symbol Importance Ranking\n**Goal:** Use call graph analysis to rank symbol importance\n\n```python\n# Example:\n# {\n#   \"name\": \"authenticate\",\n#   \"importance\": \"critical\",  # PageRank in top 5%\n#   \"importance_score\": 0.87,\n#   \"is_entry_point\": true  # Called by many, calls few\n# }\n```\n\n**Implementation:**\n- [ ] Build call graph from relationships table\n- [ ] Compute PageRank scores (use networkx)\n- [ ] Add importance_score and importance tier (low/medium/high/critical)\n- [ ] Flag entry points (high in-degree, low out-degree)\n\n**Tests:**\n- [ ] Test semantic relevance with fuzzy targets\n- [ ] Test usage frequency calculation accuracy\n- [ ] Test doc quality scoring\n- [ ] Test related symbols suggestions\n- [ ] Test cross-language variant detection\n- [ ] Test importance ranking with call graph\n\n---\n\n## Phase 3: Performance & Polish\n\n### Task 3.1: Performance Optimization\n**Target:** <50ms for typical files, <200ms for large files\n\n- [ ] Profile current implementation\n- [ ] Cache embeddings for symbols (avoid recomputation)\n- [ ] Lazy load body content (only compute if mode=\"full\")\n- [ ] Batch database queries\n- [ ] Add performance logging\n\n### Task 3.2: Output Format & Agent UX\n**Goal:** Make output maximally useful for agents\n\n- [ ] Add structured JSON output (easy to parse)\n- [ ] Add markdown tree view option (human-readable)\n- [ ] Include file metadata (language, LOC, symbol count)\n- [ ] Add next_actions suggestions based on results\n- [ ] Include query performance metrics\n\n### Task 3.3: Error Handling & Edge Cases\n- [ ] Handle binary files gracefully\n- [ ] Handle very large files (>10k lines)\n- [ ] Handle unparseable code (syntax errors)\n- [ ] Handle missing embeddings gracefully\n- [ ] Handle empty files\n\n### Task 3.4: Documentation\n- [ ] Update TOOLS_PLAN.md with final implementation\n- [ ] Add usage examples for each mode\n- [ ] Document all parameters and defaults\n- [ ] Add troubleshooting guide\n\n**Tests:**\n- [ ] Benchmark against Julie (should be faster)\n- [ ] Test with 100+ file corpus\n- [ ] Test error handling with malformed files\n- [ ] Test output format parsing by agents\n\n---\n\n## Implementation Notes\n\n### Key Design Decisions\n\n1. **Compute semantic features lazily**\n   - Only compute embeddings/relevance when target specified\n   - Avoid expensive operations for simple structure queries\n\n2. **Cache aggressively**\n   - Cache embeddings in vector_store\n   - Cache call graph PageRank scores\n   - Invalidate on file changes\n\n3. **Graceful degradation**\n   - If embeddings unavailable, skip semantic features\n   - If relationships table empty, skip usage frequency\n   - Always return basic structure (never fail completely)\n\n4. **Agent-first output**\n   - Structured JSON for programmatic access\n   - Include metadata agents need (relevance, usage, docs)\n   - Provide next_actions suggestions\n\n### Python Libraries to Use\n\n- `miller_core` - Tree-sitter parsing (already implemented)\n- `networkx` - Call graph analysis, PageRank\n- `numpy` - Vector operations\n- `sentence-transformers` - Already integrated for embeddings\n\n### Test Strategy\n\n1. **Unit tests** for each mode/feature\n2. **Integration tests** with real codebases\n3. **Performance tests** with large files\n4. **Comparison tests** against Julie's output (validate parity)\n\n---\n\n## Milestones\n\n- **M1: Feature Parity** - All Julie features working (1-2 days)\n- **M2: Semantic Enhancements** - ML features implemented (2-3 days)\n- **M3: Performance & Polish** - Optimized and documented (1 day)\n\n**Total Estimate:** 4-6 days of focused work\n\n---\n\n## Success Metrics\n\n**Quantitative:**\n- Performance: <50ms typical, <200ms large files\n- Feature coverage: 100% parity + 6 enhancements\n- Test coverage: >90% of get_symbols code\n\n**Qualitative:**\n- Agent feedback: \"get_symbols gives me everything I need to understand code\"\n- Human feedback: \"Best code overview tool I've used for onboarding\"\n- Comparison: \"Noticeably better than Julie's get_symbols\"\n\n---\n\n## Next Steps After Completion\n\n1. Update TOOLS_PLAN.md with final implementation details\n2. Create usage examples in documentation\n3. Gather early user feedback\n4. Move on to fast_refs implementation",
  "git": {
    "branch": "main",
    "commit": "7e83742",
    "dirty": true,
    "files_changed": [
      ".memories/2025-11-19/122349_727b.json",
      ".memories/2025-11-19/131950_43ff.json"
    ]
  },
  "id": "plan_complete-getsymbols-better-than-julie",
  "status": "active",
  "timestamp": 1763580121,
  "title": "Complete get_symbols - Better Than Julie",
  "type": "plan"
}
