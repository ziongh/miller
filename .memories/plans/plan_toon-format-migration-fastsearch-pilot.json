{
  "content": "## Goal\nImplement TOON format support in `fast_search` tool to achieve 30-60% token reduction for symbol search results. Use Julie's proven three-mode approach (json/toon/auto) as reference.\n\n## Success Criteria\n- [ ] `fast_search` supports `output_format` parameter: \"json\" (default), \"toon\", \"auto\"\n- [ ] TOON mode returns text-only (no structured content duplication)\n- [ ] JSON mode returns structured-only (no text duplication)\n- [ ] Auto mode uses TOON for large responses (\u226520 results), JSON for small\n- [ ] Graceful fallback to JSON if TOON encoding fails\n- [ ] Token count reduction measured: Target 30-40% for 50+ result queries\n- [ ] All existing tests pass (backward compatibility)\n- [ ] New tests added for TOON encoding/decoding\n\n## Implementation Steps\n\n### Phase 1: Setup & Dependencies\n- [ ] Add `toon-format>=0.9` to `pyproject.toml`\n- [ ] Install: `uv pip install toon-format`\n- [ ] Test TOON import: `from toon_format import encode, decode`\n- [ ] Read TOON docs for Python usage patterns\n\n### Phase 2: Data Structure Adaptation\n- [ ] Create `ToonSymbol` class/dict with primitives only\n  - Convert from current Symbol dict format\n  - String types for: id, name, kind, language, file_path\n  - Numbers: start_line, end_line\n  - Optional: signature, doc_comment, confidence (float)\n- [ ] Test TOON encoding with sample symbol list\n  ```python\n  sample = [\n      {\"name\": \"UserService\", \"kind\": \"Class\", \"file_path\": \"user.py\", \"line\": 10},\n      {\"name\": \"get_user\", \"kind\": \"Method\", \"file_path\": \"user.py\", \"line\": 15}\n  ]\n  toon_str = encode(sample)\n  decoded = decode(toon_str)\n  assert decoded == sample\n  ```\n\n### Phase 3: Modify fast_search Signature\n**Current:**\n```python\nasync def fast_search(\n    query: str,\n    method: Literal[\"auto\", \"text\", \"pattern\", \"semantic\", \"hybrid\"] = \"auto\",\n    limit: int = 50,\n    workspace_id: Optional[str] = None,\n) -> list[dict[str, Any]]:\n```\n\n**New:**\n```python\nasync def fast_search(\n    query: str,\n    method: Literal[\"auto\", \"text\", \"pattern\", \"semantic\", \"hybrid\"] = \"auto\",\n    limit: int = 50,\n    workspace_id: Optional[str] = None,\n    output_format: Literal[\"json\", \"toon\", \"auto\"] = \"json\",  # NEW\n) -> Union[list[dict[str, Any]], str]:  # Can return TOON string\n```\n\n### Phase 4: Implement Three-Mode Logic\n```python\n# After getting results from vector_store.search()\nformatted_results = [format_symbol(r) for r in results]\n\n# Mode selection\nif output_format == \"toon\":\n    return encode_toon(formatted_results)\nelif output_format == \"auto\":\n    if len(formatted_results) >= 20:  # Threshold\n        return encode_toon(formatted_results, fallback=True)\n    else:\n        return formatted_results  # JSON\nelse:  # \"json\"\n    return formatted_results\n```\n\n**Helper functions:**\n- [ ] `encode_toon(data, fallback=False)` - Encode to TOON with optional JSON fallback\n- [ ] `format_symbol_for_toon(symbol)` - Convert Symbol to TOON-friendly dict\n\n### Phase 5: FastMCP Integration\nCurrent FastMCP likely auto-JSONifies return values. Check if it handles string returns properly:\n- [ ] Test: Does FastMCP send string returns as-is (for TOON)?\n- [ ] If not: Return `TextContent` object for TOON mode\n  ```python\n  if output_format == \"toon\":\n      toon_str = encode(formatted_results)\n      return {\"content\": [{\"type\": \"text\", \"text\": toon_str}]}\n  ```\n\n### Phase 6: Testing\n**Unit Tests:**\n- [ ] Test TOON encoding of symbol list (2, 10, 50 symbols)\n- [ ] Test decode \u2192 encode \u2192 decode roundtrip\n- [ ] Test fallback when TOON encoding fails\n- [ ] Test auto mode threshold (19 results \u2192 JSON, 20 results \u2192 TOON)\n\n**Integration Tests:**\n- [ ] Query that returns 5 results (should be JSON in auto mode)\n- [ ] Query that returns 50 results (should be TOON in auto mode)\n- [ ] Explicitly request \"toon\" format\n- [ ] Explicitly request \"json\" format\n\n**Token Measurement:**\n```python\nimport tiktoken\nenc = tiktoken.encoding_for_model(\"gpt-4\")\n\njson_str = json.dumps(results)\ntoon_str = encode(results)\n\njson_tokens = len(enc.encode(json_str))\ntoon_tokens = len(enc.encode(toon_str))\nreduction = (json_tokens - toon_tokens) / json_tokens * 100\n\nprint(f\"JSON: {json_tokens} tokens\")\nprint(f\"TOON: {toon_tokens} tokens\")\nprint(f\"Reduction: {reduction:.1f}%\")\n```\n\n### Phase 7: Documentation\n- [ ] Update `fast_search` docstring with `output_format` parameter\n- [ ] Add examples of TOON usage\n- [ ] Document token savings in CLAUDE.md\n- [ ] Update TODO.md Phase 1 checklist\n\n## Reference: Julie's Implementation\nStudy these files in `~/source/julie`:\n- `src/tools/shared.rs` \u2192 `create_toonable_result()` (three-mode logic)\n- `src/tools/search/formatting.rs` \u2192 `ToonSymbol` struct, TOON encoding\n- `src/tests/tools/search/toon_formatting_tests.rs` \u2192 Test patterns\n\n## Edge Cases to Handle\n- Empty results (0 symbols) \u2192 Return empty array in both formats\n- TOON encoding failure \u2192 Fallback to JSON with warning log\n- Very large results (500+ symbols) \u2192 TOON should handle well (CSV-style)\n- Special characters in symbol names \u2192 TOON should escape properly\n- Optional fields (None values) \u2192 TOON should handle or omit\n\n## Rollback Plan\nIf TOON causes issues:\n1. Default stays \"json\" (backward compatible)\n2. Can disable TOON by always returning JSON\n3. Remove `output_format` parameter in future if unused\n\n## Metrics to Track\n- Token reduction %: Target 30-40% for 50+ results\n- Encoding overhead: Should be < 10ms\n- Decode success rate: Should be 100% (roundtrip test)\n- Client compatibility: Does Claude Code parse TOON correctly?\n\n## Next Steps After Pilot\nIf successful:\n1. Extend to `trace_call_path` (highest impact - nested trees)\n2. Extend to `get_symbols`, `fast_refs`\n3. Consider making \"auto\" the default (after validation)\n4. Measure aggregate token savings across all tools\n",
  "git": {
    "branch": "main",
    "commit": "57f38e0",
    "dirty": false,
    "files_changed": []
  },
  "id": "plan_toon-format-migration-fastsearch-pilot",
  "status": "pending",
  "timestamp": 1763670995,
  "title": "TOON Format Migration - fast_search Pilot",
  "type": "plan"
}
