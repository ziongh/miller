---
git:
  branch: main
  commit: '8834447'
  dirty: true
  files_changed:
  - python/miller/embeddings/manager.py
  - .memories/2025-11-26/163911_4c23.md
id: checkpoint_b5576f0d_a5682f
tags:
- bugfix
- directml
- embeddings
- oom
- batch-size
timestamp: 1764197038
type: checkpoint
---

Fixed DirectML OOM error during batch embedding: reduced batch_size from 256 to 32 for DirectML devices. The large batch was trying to allocate 3GB for attention matrices which exceeded GPU VRAM. Now uses device-specific batch sizes: DirectML=32, CUDA=256, CPU/other=64.
